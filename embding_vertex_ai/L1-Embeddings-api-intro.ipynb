{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/arnabnandy7/llm_notebooks/blob/main/L1-Embeddings-api-intro.ipynb","timestamp":1699973756469}],"authorship_tag":"ABX9TyOMXMrpVN+YcLDu1hukpkFV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_hyQe5-AR1Df"},"outputs":[],"source":["# Getting Started With Text Embeddings"]},{"cell_type":"code","source":["#### Project environment setup\n","\n","- Load credentials and relevant Python Libraries\n","- If you were running this notebook locally, you would first install Vertex AI.  In this classroom, this is already installed.\n","```Python\n","!pip install google-cloud-aiplatform\n","```\n"],"metadata":{"id":"8T8_CO8VUVVG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from utils import authenticate\n","credentials, PROJECT_ID = authenticate() # Get credentials and project ID"],"metadata":{"id":"VZ7QuLiKUXiN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Enter project details"],"metadata":{"id":"EIrLAhcrUZCH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(PROJECT_ID)"],"metadata":{"id":"8RsF-HraUag1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["REGION = 'us-central1'"],"metadata":{"id":"3nQ7pYYUUcQY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import and initialize the Vertex AI Python SDK\n","\n","import vertexai\n","vertexai.init(project = PROJECT_ID,\n","              location = REGION,\n","              credentials = credentials)"],"metadata":{"id":"b7jQYJ4zUfQA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Use the embeddings model\n","- Import and load the model."],"metadata":{"id":"cGKnS358Uf4c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from vertexai.language_models import TextEmbeddingModel"],"metadata":{"id":"ZW6IYn_1UhZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_model = TextEmbeddingModel.from_pretrained(\n","    \"textembedding-gecko@001\")"],"metadata":{"id":"VRdviQrUUiyP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- Generate a word embedding"],"metadata":{"id":"F_UUB4oPUj-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding = embedding_model.get_embeddings(\n","    [\"life\"])"],"metadata":{"id":"FE8BQN-2Umxm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- The returned object is a list with a single `TextEmbedding` object.\n","- The `TextEmbedding.values` field stores the embeddings in a Python list."],"metadata":{"id":"J-IWX8WwUoH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector = embedding[0].values\n","print(f\"Length = {len(vector)}\")\n","print(vector[:10])"],"metadata":{"id":"XjdTIjnuUpmo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- Generate a sentence embedding."],"metadata":{"id":"1T1byxNHUrbd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding = embedding_model.get_embeddings(\n","    [\"What is the meaning of life?\"])"],"metadata":{"id":"vUbGjuX-UtDb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector = embedding[0].values\n","print(f\"Length = {len(vector)}\")\n","print(vector[:10])"],"metadata":{"id":"YvEKt1QBUuow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Similarity\n","\n","- Calculate the similarity between two sentences as a number between 0 and 1.\n","- Try out your own sentences and check if the similarity calculations match your intuition."],"metadata":{"id":"5WTWE9lSUv2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity"],"metadata":{"id":"dASxCxZPUxhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emb_1 = embedding_model.get_embeddings(\n","    [\"What is the meaning of life?\"]) # 42!\n","\n","emb_2 = embedding_model.get_embeddings(\n","    [\"How does one spend their time well on Earth?\"])\n","\n","emb_3 = embedding_model.get_embeddings(\n","    [\"Would you like a salad?\"])\n","\n","vec_1 = [emb_1[0].values]\n","vec_2 = [emb_2[0].values]\n","vec_3 = [emb_3[0].values]"],"metadata":{"id":"uv9ifMuxUy1O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- Note: the reason we wrap the embeddings (a Python list) in another list is because the `cosine_similarity` function expects either a 2D numpy array or a list of lists.\n","```Python\n","vec_1 = [emb_1[0].values]\n","```"],"metadata":{"id":"3DoBodfjU0YT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(cosine_similarity(vec_1,vec_2))\n","print(cosine_similarity(vec_2,vec_3))\n","print(cosine_similarity(vec_1,vec_3))"],"metadata":{"id":"CyBNSJqjU10i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### From word to sentence embeddings\n","- One possible way to calculate sentence embeddings from word embeddings is to take the average of the word embeddings.\n","- This ignores word order and context, so two sentences with different meanings, but the same set of words will end up with the same sentence embedding."],"metadata":{"id":"JNYFFRHzU3Bt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["in_1 = \"The kids play in the park.\"\n","in_2 = \"The play was for kids in the park.\""],"metadata":{"id":"1qSLp7G8U4je"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- Remove stop words like [\"the\", \"in\", \"for\", \"an\", \"is\"] and punctuation."],"metadata":{"id":"KifL3J-rU6BO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["in_pp_1 = [\"kids\", \"play\", \"park\"]\n","in_pp_2 = [\"play\", \"kids\", \"park\"]"],"metadata":{"id":"UzWrIjGWU7KY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- Generate one embedding for each word.  So this is a list of three lists."],"metadata":{"id":"uR26z3b6U8SS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings_1 = [emb.values for emb in embedding_model.get_embeddings(in_pp_1)]"],"metadata":{"id":"2kZUUZPkU9hc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- Use numpy to convert this list of lists into a 2D array of 3 rows and 768 columns."],"metadata":{"id":"R6a_v1q5U_MS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","emb_array_1 = np.stack(embeddings_1)\n","print(emb_array_1.shape)"],"metadata":{"id":"ZP4VfF1MVAtY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings_2 = [emb.values for emb in embedding_model.get_embeddings(in_pp_2)]\n","emb_array_2 = np.stack(embeddings_2)\n","print(emb_array_2.shape)"],"metadata":{"id":"h0r3BB7hVB78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- Take the average embedding across the 3 word embeddings\n","- You'll get a single embedding of length 768."],"metadata":{"id":"okqk2g2nVDcd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emb_1_mean = emb_array_1.mean(axis = 0)\n","print(emb_1_mean.shape)"],"metadata":{"id":"cLoYxg3LVE0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emb_2_mean = emb_array_2.mean(axis = 0)"],"metadata":{"id":"muo6dDtZVGHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- Check to see that taking an average of word embeddings results in two sentence embeddings that are identical."],"metadata":{"id":"k84bRrkiVHpC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(emb_1_mean[:4])\n","print(emb_2_mean[:4])"],"metadata":{"id":"oWZDmJ5GVI8m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Get sentence embeddings from the model.\n","- These sentence embeddings account for word order and context.\n","- Verify that the sentence embeddings are not the same."],"metadata":{"id":"uT3H2MmHVJ_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(in_1)\n","print(in_2)"],"metadata":{"id":"fsskhgpUVLfr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_1 = embedding_model.get_embeddings([in_1])\n","embedding_2 = embedding_model.get_embeddings([in_2])"],"metadata":{"id":"JBXqEvFJVMg1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector_1 = embedding_1[0].values\n","print(vector_1[:4])\n","vector_2 = embedding_2[0].values\n","print(vector_2[:4])"],"metadata":{"id":"0ixWjkSRVNmc"},"execution_count":null,"outputs":[]}]}