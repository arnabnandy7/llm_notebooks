{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOofFmolYlabrU95v/gYJUL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"e8sRlZz19zIv"},"outputs":[],"source":["# L3: Image generation app ðŸŽ¨"]},{"cell_type":"code","source":["Load your HF API key and relevant Python libraries"],"metadata":{"id":"QNyTSzjJ-5W8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import io\n","import IPython.display\n","from PIL import Image\n","import base64\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv()) # read local .env file\n","hf_api_key = os.environ['HF_API_KEY']"],"metadata":{"id":"bweMzwsm-6XX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper function\n","import requests, json\n","\n","#Text-to-image endpoint\n","def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n","    headers = {\n","      \"Authorization\": f\"Bearer {hf_api_key}\",\n","      \"Content-Type\": \"application/json\"\n","    }\n","    data = { \"inputs\": inputs }\n","    if parameters is not None:\n","        data.update({\"parameters\": parameters})\n","    response = requests.request(\"POST\",\n","                                ENDPOINT_URL,\n","                                headers=headers,\n","                                data=json.dumps(data))\n","    return json.loads(response.content.decode(\"utf-8\"))"],"metadata":{"id":"ufxjx_Aw-73g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Building an image generation app"],"metadata":{"id":"QiXO-6G5-9gY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Here we are going to run `runwayml/stable-diffusion-v1-5` using the `ðŸ§¨ diffusers` library."],"metadata":{"id":"0MPkj9nz--dA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### How about running it locally?\n","The code would look very similar if you were running it locally instead of from an API.\n","```py\n","from diffusers import DiffusionPipeline\n","\n","pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n","\n","def get_completion(prompt):\n","    return pipeline(prompt).images[0]\n","```"],"metadata":{"id":"hauuCjwi-_Vi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"a dog in a park\"\n","\n","result = get_completion(prompt)\n","IPython.display.HTML(f'<img src=\"data:image/png;base64,{result}\" />')"],"metadata":{"id":"ZiKV3tv3_BAG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Generating with `gr.Interface()`"],"metadata":{"id":"o4uZrgK5_B80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","\n","#A helper function to convert the PIL image to base64\n","#so you can send it to the API\n","def base64_to_pil(img_base64):\n","    base64_decoded = base64.b64decode(img_base64)\n","    byte_stream = io.BytesIO(base64_decoded)\n","    pil_image = Image.open(byte_stream)\n","    return pil_image\n","\n","def generate(prompt):\n","    output = get_completion(prompt)\n","    result_image = base64_to_pil(output)\n","    return result_image\n","\n","gr.close_all()\n","demo = gr.Interface(fn=generate,\n","                    inputs=[gr.Textbox(label=\"Your prompt\")],\n","                    outputs=[gr.Image(label=\"Result\")],\n","                    title=\"Image Generation with Stable Diffusion\",\n","                    description=\"Generate any image with Stable Diffusion\",\n","                    allow_flagging=\"never\",\n","                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n","\n","demo.launch(share=True, server_port=int(os.environ['PORT1']))"],"metadata":{"id":"I0w5why-_C_C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo.close()"],"metadata":{"id":"dmzneZ26_EME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Building a more advanced interface"],"metadata":{"id":"WozGzIni_E-w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","\n","#A helper function to convert the PIL image to base64\n","# so you can send it to the API\n","def base64_to_pil(img_base64):\n","    base64_decoded = base64.b64decode(img_base64)\n","    byte_stream = io.BytesIO(base64_decoded)\n","    pil_image = Image.open(byte_stream)\n","    return pil_image\n","\n","def generate(prompt, negative_prompt, steps, guidance, width, height):\n","    params = {\n","        \"negative_prompt\": negative_prompt,\n","        \"num_inference_steps\": steps,\n","        \"guidance_scale\": guidance,\n","        \"width\": width,\n","        \"height\": height\n","    }\n","\n","    output = get_completion(prompt, params)\n","    pil_image = base64_to_pil(output)\n","    return pil_image\n","\n","gr.close_all()\n","demo = gr.Interface(fn=generate,\n","                    inputs=[\n","                        gr.Textbox(label=\"Your prompt\"),\n","                        gr.Textbox(label=\"Negative prompt\"),\n","                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n","                                 info=\"In how many steps will the denoiser denoise the image?\"),\n","                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n","                                  info=\"Controls how much the text prompt influences the result\"),\n","                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n","                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n","                    ],\n","                    outputs=[gr.Image(label=\"Result\")],\n","                    title=\"Image Generation with Stable Diffusion\",\n","                    description=\"Generate any image with Stable Diffusion\",\n","                    allow_flagging=\"never\"\n","                    )\n","\n","demo.launch(share=True, server_port=int(os.environ['PORT2']))"],"metadata":{"id":"L50cbhAW_GGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo.close()"],"metadata":{"id":"YSEdTaGj_Hd_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## `gr.Blocks()` to the rescue!"],"metadata":{"id":"ULoVs8B2_Iaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with gr.Blocks() as demo:\n","    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n","    prompt = gr.Textbox(label=\"Your prompt\")\n","    with gr.Row():\n","        with gr.Column():\n","            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n","            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n","                      info=\"In many steps will the denoiser denoise the image?\")\n","            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n","                      info=\"Controls how much the text prompt influences the result\")\n","            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n","            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n","            btn = gr.Button(\"Submit\")\n","        with gr.Column():\n","            output = gr.Image(label=\"Result\")\n","\n","    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n","gr.close_all()\n","demo.launch(share=True, server_port=int(os.environ['PORT3']))"],"metadata":{"id":"wQ2IBjEy_JSO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with gr.Blocks() as demo:\n","    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n","    with gr.Row():\n","        with gr.Column(scale=4):\n","            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n","        with gr.Column(scale=1, min_width=50):\n","            btn = gr.Button(\"Submit\") #Submit button side by side!\n","    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n","            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n","            with gr.Row():\n","                with gr.Column():\n","                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n","                      info=\"In many steps will the denoiser denoise the image?\")\n","                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n","                      info=\"Controls how much the text prompt influences the result\")\n","                with gr.Column():\n","                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n","                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n","    output = gr.Image(label=\"Result\") #Move the output up too\n","\n","    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n","\n","gr.close_all()\n","demo.launch(share=True, server_port=int(os.environ['PORT4']))"],"metadata":{"id":"DHoWfoJW_Kdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gr.close_all()"],"metadata":{"id":"h5ktfRQR_LqM"},"execution_count":null,"outputs":[]}]}