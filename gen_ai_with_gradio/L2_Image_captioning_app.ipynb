{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZd6iypn1ps/Oo/5AxSIfW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-UuepKHqMUTs"},"outputs":[],"source":["# L2: Image captioning app üñºÔ∏èüìù"]},{"cell_type":"code","source":["Load your HF API key and relevant Python libraries"],"metadata":{"id":"K50og_W39g96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import io\n","import IPython.display\n","from PIL import Image\n","import base64\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv()) # read local .env file\n","hf_api_key = os.environ['HF_API_KEY']"],"metadata":{"id":"roDSUUJ89iOe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper functions\n","import requests, json\n","\n","#Image-to-text endpoint\n","def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_ITT_BASE']):\n","    headers = {\n","      \"Authorization\": f\"Bearer {hf_api_key}\",\n","      \"Content-Type\": \"application/json\"\n","    }\n","    data = { \"inputs\": inputs }\n","    if parameters is not None:\n","        data.update({\"parameters\": parameters})\n","    response = requests.request(\"POST\",\n","                                ENDPOINT_URL,\n","                                headers=headers,\n","                                data=json.dumps(data))\n","    return json.loads(response.content.decode(\"utf-8\"))"],"metadata":{"id":"hcTsQOj79jbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Building an image captioning app"],"metadata":{"id":"EWNGkuQy9mYF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Here we'll be using an [Inference Endpoint](https://huggingface.co/inference-endpoints) for `Salesforce/blip-image-captioning-base` a 14M parameter captioning model."],"metadata":{"id":"MFnPreX19nz4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["The code would look very similar if you were running it locally instead of from an API. You can check the [Pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines) documentation page.\n","\n","```py\n","from transformers import pipeline\n","\n","get_completion = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n","\n","def summarize(input):\n","    output = get_completion(input)\n","    return output[0]['generated_text']\n","\n","```"],"metadata":{"id":"23fsjwgb9pFQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["The free images are available on: https://free-images.com/"],"metadata":{"id":"K833upCO9qa8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_url = \"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"\n","display(IPython.display.Image(url=image_url))\n","get_completion(image_url)"],"metadata":{"id":"gM-pHL5Q9ryg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","\n","def image_to_base64_str(pil_image):\n","    byte_arr = io.BytesIO()\n","    pil_image.save(byte_arr, format='PNG')\n","    byte_arr = byte_arr.getvalue()\n","    return str(base64.b64encode(byte_arr).decode('utf-8'))\n","\n","def captioner(image):\n","    base64_image = image_to_base64_str(image)\n","    result = get_completion(base64_image)\n","    return result[0]['generated_text']\n","\n","gr.close_all()\n","demo = gr.Interface(fn=captioner,\n","                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n","                    outputs=[gr.Textbox(label=\"Caption\")],\n","                    title=\"Image Captioning with BLIP\",\n","                    description=\"Caption any image using the BLIP model\",\n","                    allow_flagging=\"never\",\n","                    examples=[\"christmas_dog.jpeg\", \"bird_flight.jpeg\", \"cow.jpeg\"])\n","\n","demo.launch(share=True, server_port=int(os.environ['PORT1']))"],"metadata":{"id":"0UvXVSPw9tHr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gr.close_all()"],"metadata":{"id":"GgKaDGj09u5h"},"execution_count":null,"outputs":[]}]}