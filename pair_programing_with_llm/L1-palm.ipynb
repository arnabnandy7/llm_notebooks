{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgvX9xPStzcHKixvpGUfMT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QqNWqHZPPs1A"},"outputs":[],"source":["# Lesson 1: Getting Started with PaLM"]},{"cell_type":"code","source":["#### Setup\n","Set the MakerSuite API key with the provided helper function."],"metadata":{"id":"svqcTz3vP4R3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from utils import get_api_key"],"metadata":{"id":"FX91AzVuP5UT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["In this classroom, we've installed the relevant libraries for you.\n","\n","If you wanted to use the PaLM API on your own machine, you would first install the library:\n","```Python\n","!pip install -q google.generativeai\n","```\n","The optional flag `-q` installs \"quietly\" without printing out details of the installation.\n"],"metadata":{"id":"NDkeXjmcP6gN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import google.generativeai as palm\n","from google.api_core import client_options as client_options_lib\n","\n","palm.configure(\n","    api_key=get_api_key(),\n","    transport=\"rest\",\n","    client_options=client_options_lib.ClientOptions(\n","        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n","    )\n",")"],"metadata":{"id":"filnH43fP8LA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Explore the available models"],"metadata":{"id":"dKoTAot1P9r0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for m in palm.list_models():\n","    print(f\"name: {m.name}\")\n","    print(f\"description: {m.description}\")\n","    print(f\"generation methods:{m.supported_generation_methods}\\n\")"],"metadata":{"id":"10CgCFvFP-7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Filter models by their supported generation methods\n","- `generateText` is currently recommended for coding-related prompts.\n","- `generateMessage` is optimized for multi-turn chats (dialogues) with an LLM."],"metadata":{"id":"pvVwIoGtQAO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = [m for m in palm.list_models()\n","          if 'generateText'\n","          in m.supported_generation_methods]\n","models"],"metadata":{"id":"nmtVOu5GQBhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_bison = models[0]\n","model_bison"],"metadata":{"id":"t0mQGz3xQCnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### helper function to generate text\n","\n","- The `@retry` decorator helps you to retry the API call if it fails.\n","- We set the temperature to 0.0 so that the model returns the same output (completion) if given the same input (the prompt)."],"metadata":{"id":"IKQdUN0gQEAp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.api_core import retry\n","@retry.Retry()\n","def generate_text(prompt,\n","                  model=model_bison,\n","                  temperature=0.0):\n","    return palm.generate_text(prompt=prompt,\n","                              model=model,\n","                              temperature=temperature)"],"metadata":{"id":"_wxGorKcQFWO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Ask the LLM how to write some code\n","\n"],"metadata":{"id":"SMEubnMeQHFS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"Show me how to iterate across a list in Python.\""],"metadata":{"id":"GqOqXiJiQIVs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["completion = generate_text(prompt)"],"metadata":{"id":"OrC31sbXQJoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(completion.result)"],"metadata":{"id":"1O7XA7POQK2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["- Tip: The words \"show me\" tends to encourage the PaLM LLM to give more details and explanations compared to if you were to ask \"write code to ...\""],"metadata":{"id":"xbGUrqCHQL7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"write code to iterate across a list in Python\""],"metadata":{"id":"QVpRaPFEQNKM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["completion = generate_text(prompt)\n","print(completion.result)"],"metadata":{"id":"8IXmjKi8QO1V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Try out the code\n","- Try copy-pasting some of the generated code and running it in the notebook.\n","- Remember to test out the LLM-generated code and debug it make sure it works as intended."],"metadata":{"id":"xrGxoxt0QP12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# paste the LLM's code here\n","\n","\n"],"metadata":{"id":"Sc_iAXHUQRFM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Try asking your own coding question"],"metadata":{"id":"F4bGFDr9QSTc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modify the prompt with your own question\n","prompt = \"Show me how to [...]\"\n","\n","completion = generate_text(prompt)"],"metadata":{"id":"evpEKPhxQT6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xjlZgiBCQVD5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Note about the API key\n","We've provided an API key for this classroom.  If you would like your own API key for your own projects, you can get one at [developers.generativeai.google](https://developers.generativeai.google/)"],"metadata":{"id":"mg0XBO6iQWI4"},"execution_count":null,"outputs":[]}]}