{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOyRHyiRN1yoxNgsIJXFwbB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"G1nG0P1d6Js-"},"outputs":[],"source":["# Sampling from a diffusion model\n","\n","<!--- @wandbcode{dlai_03} -->\n","\n","In this notebook we will sample from the previously trained diffusion model.\n","- We are going to compare the samples from DDPM and DDIM samplers\n","- Visualize mixing samples with conditional diffusion models"]},{"cell_type":"code","source":["from pathlib import Path\n","from types import SimpleNamespace\n","import torch\n","import torch.nn.functional as F\n","import numpy as np\n","from utilities import *\n","\n","import wandb"],"metadata":{"id":"dOJp6YSE8cxJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wandb.login(anonymous=\"allow\")"],"metadata":{"id":"tIRBMeWx8erZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setting Things Up"],"metadata":{"id":"7DQ0_F-f8f5J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Wandb Params\n","MODEL_ARTIFACT = \"dlai-course/model-registry/SpriteGen:latest\"\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","config = SimpleNamespace(\n","    # hyperparameters\n","    num_samples = 30,\n","\n","    # ddpm sampler hyperparameters\n","    timesteps = 500,\n","    beta1 = 1e-4,\n","    beta2 = 0.02,\n","\n","    # ddim sampler hp\n","    ddim_n = 25,\n","\n","    # network hyperparameters\n","    height = 16,\n",")"],"metadata":{"id":"t7X0NgMY8g8F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["In the previous notebook we saved the best model as a wandb Artifact (our way of storing files during runs). We will now load the model from wandb and set up the sampling loop."],"metadata":{"id":"yMKLUzqu8ifv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_model(model_artifact_name):\n","    \"Load the model from wandb artifacts\"\n","    api = wandb.Api()\n","    artifact = api.artifact(model_artifact_name, type=\"model\")\n","    model_path = Path(artifact.download())\n","\n","    # recover model info from the registry\n","    producer_run = artifact.logged_by()\n","\n","    # load the weights dictionary\n","    model_weights = torch.load(model_path/\"context_model.pth\",\n","                               map_location=\"cpu\")\n","\n","    # create the model\n","    model = ContextUnet(in_channels=3,\n","                        n_feat=producer_run.config[\"n_feat\"],\n","                        n_cfeat=producer_run.config[\"n_cfeat\"],\n","                        height=producer_run.config[\"height\"])\n","\n","    # load the weights into the model\n","    model.load_state_dict(model_weights)\n","\n","    # set the model to eval mode\n","    model.eval()\n","    return model.to(DEVICE)"],"metadata":{"id":"5ZCanfBP8j94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nn_model = load_model(MODEL_ARTIFACT)"],"metadata":{"id":"aZqC8qHG8l3V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Sampling"],"metadata":{"id":"5xSr_nWu8nN2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["We will sample and log the generated samples to wandb."],"metadata":{"id":"fIxQUXYA8oZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, sample_ddpm_context = setup_ddpm(config.beta1,\n","                                    config.beta2,\n","                                    config.timesteps,\n","                                    DEVICE)"],"metadata":{"id":"74uPhC278yK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Let's define a set of noises and a context vector to condition on."],"metadata":{"id":"lv4cch3V8zaP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Noise vector\n","# x_T ~ N(0, 1), sample initial noise\n","noises = torch.randn(config.num_samples, 3,\n","                     config.height, config.height).to(DEVICE)\n","\n","# A fixed context vector to sample from\n","ctx_vector = F.one_hot(torch.tensor([0,0,0,0,0,0,   # hero\n","                                     1,1,1,1,1,1,   # non-hero\n","                                     2,2,2,2,2,2,   # food\n","                                     3,3,3,3,3,3,   # spell\n","                                     4,4,4,4,4,4]), # side-facing\n","                       5).to(DEVICE).float()"],"metadata":{"id":"AFdkavLS80w0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Let's bring that faster DDIM sampler from the diffusion course."],"metadata":{"id":"3yEnS37i82Ge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_ddim_context = setup_ddim(config.beta1,\n","                                 config.beta2,\n","                                 config.timesteps,\n","                                 DEVICE)"],"metadata":{"id":"_UGbOUnr83Lx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Sampling:\n","let's compute ddpm samples as before"],"metadata":{"id":"7czOJ19E84bl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ddpm_samples, _ = sample_ddpm_context(nn_model, noises, ctx_vector)"],"metadata":{"id":"h8_i8NCh85jA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["For DDIM we can control the step size by the `n` param:"],"metadata":{"id":"3V63uJg086xQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ddim_samples, _ = sample_ddim_context(nn_model,\n","                                      noises,\n","                                      ctx_vector,\n","                                      n=config.ddim_n)"],"metadata":{"id":"Rd5iEDwd874r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Visualizing generations on a Table\n","Let's create a `wandb.Table` to store our generations"],"metadata":{"id":"SHPo2nPD88mh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["table = wandb.Table(columns=[\"input_noise\", \"ddpm\", \"ddim\", \"class\"])"],"metadata":{"id":"JKzxqzDJ8-Jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["We can add the rows to the table one by one, we also cast images to `wandb.Image` so we can render them correctly in the UI"],"metadata":{"id":"oqzZww3x8_Yg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for noise, ddpm_s, ddim_s, c in zip(noises,\n","                                    ddpm_samples,\n","                                    ddim_samples,\n","                                    to_classes(ctx_vector)):\n","\n","    # add data row by row to the Table\n","    table.add_data(wandb.Image(noise),\n","                   wandb.Image(ddpm_s),\n","                   wandb.Image(ddim_s),\n","                   c)"],"metadata":{"id":"qKbiWKx19AiU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["we log the table to W&B, we can also use `wandb.init` as a context manager, this way we ensure that the run is finished when exiting the manager."],"metadata":{"id":"V7iMjauj9CPZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with wandb.init(project=\"dlai_sprite_diffusion\",\n","                job_type=\"samplers_battle\",\n","                config=config):\n","\n","    wandb.log({\"samplers_table\":table})"],"metadata":{"id":"yMfv1Os79DYQ"},"execution_count":null,"outputs":[]}]}