{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7+vTCrFrUhQ9tP8GGO8BC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AUZJey2XOhIC"},"outputs":[],"source":["# Instruction-tuning"]},{"cell_type":"code","source":["import itertools\n","import jsonlines\n","\n","from datasets import load_dataset\n","from pprint import pprint\n","\n","from llama import BasicModelRunner\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"],"metadata":{"id":"2XqGu4LuSJ4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Load instruction tuned dataset"],"metadata":{"id":"FK_J46ywSK46"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)"],"metadata":{"id":"aDXbRPrGSM5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["m = 5\n","print(\"Instruction-tuned dataset:\")\n","top_m = list(itertools.islice(instruction_tuned_dataset, m))\n","for j in top_m:\n","  print(j)"],"metadata":{"id":"Draho_LrSN_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Two prompt templates"],"metadata":{"id":"7ExM74koSPHt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{instruction}\n","\n","### Input:\n","{input}\n","\n","### Response:\"\"\"\n","\n","prompt_template_without_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{instruction}\n","\n","### Response:\"\"\""],"metadata":{"id":"mzFKwQlOSQR1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Hydrate prompts (add data to prompts)"],"metadata":{"id":"NgGDsJkmSROB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["processed_data = []\n","for j in top_m:\n","  if not j[\"input\"]:\n","    processed_prompt = prompt_template_without_input.format(instruction=j[\"instruction\"])\n","  else:\n","    processed_prompt = prompt_template_with_input.format(instruction=j[\"instruction\"], input=j[\"input\"])\n","\n","  processed_data.append({\"input\": processed_prompt, \"output\": j[\"output\"]})\n"],"metadata":{"id":"fm86ZImpSSho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pprint(processed_data[0])"],"metadata":{"id":"i58cMkDzSTcC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Save data to jsonl"],"metadata":{"id":"6VMCOewySUa2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with jsonlines.open(f'alpaca_processed.jsonl', 'w') as writer:\n","    writer.write_all(processed_data)"],"metadata":{"id":"-zq7dbo5SVHG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Compare non-instruction-tuned vs. instruction-tuned models"],"metadata":{"id":"6_0zEtzASV1V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_path_hf = \"lamini/alpaca\"\n","dataset_hf = load_dataset(dataset_path_hf)\n","print(dataset_hf)"],"metadata":{"id":"hVGvRaHrSWgs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["non_instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")\n","non_instruct_output = non_instruct_model(\"Tell me how to train my dog to sit\")\n","print(\"Not instruction-tuned output (Llama 2 Base):\", non_instruct_output)"],"metadata":{"id":"YkhgoFqSSXO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")\n","instruct_output = instruct_model(\"Tell me how to train my dog to sit\")\n","print(\"Instruction-tuned output (Llama 2): \", instruct_output)"],"metadata":{"id":"OCR5DRmTSYHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chatgpt = BasicModelRunner(\"chat-gpt\")\n","instruct_output_chatgpt = chatgpt(\"Tell me how to train my dog to sit\")\n","print(\"Instruction-tuned output (ChatGPT): \", instruct_output_chatgpt)"],"metadata":{"id":"i5oONRSiSYz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Try smaller models"],"metadata":{"id":"FCSZ61q5SZ3D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n","model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")"],"metadata":{"id":"ZJyi24RrSao0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n","  # Tokenize\n","  input_ids = tokenizer.encode(\n","          text,\n","          return_tensors=\"pt\",\n","          truncation=True,\n","          max_length=max_input_tokens\n","  )\n","\n","  # Generate\n","  device = model.device\n","  generated_tokens_with_prompt = model.generate(\n","    input_ids=input_ids.to(device),\n","    max_length=max_output_tokens\n","  )\n","\n","  # Decode\n","  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n","\n","  # Strip the prompt\n","  generated_text_answer = generated_text_with_prompt[0][len(text):]\n","\n","  return generated_text_answer"],"metadata":{"id":"xJC3gsQaSbYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["finetuning_dataset_path = \"lamini/lamini_docs\"\n","finetuning_dataset = load_dataset(finetuning_dataset_path)\n","print(finetuning_dataset)"],"metadata":{"id":"diLm1ereScqq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sample = finetuning_dataset[\"test\"][0]\n","print(test_sample)\n","\n","print(inference(test_sample[\"question\"], model, tokenizer))"],"metadata":{"id":"sWBrUYtbSfud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Compare to finetuned small model"],"metadata":{"id":"lyjkYVR_Snyu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["instruction_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")"],"metadata":{"id":"5Ytw69a3Soxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(inference(test_sample[\"question\"], instruction_model, tokenizer))"],"metadata":{"id":"iibG4qhhSp2I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pssst! If you were curious how to upload your own dataset to Huggingface\n","# Here is how we did it\n","\n","# !pip install huggingface_hub\n","# !huggingface-cli login\n","\n","# import pandas as pd\n","# import datasets\n","# from datasets import Dataset\n","\n","# finetuning_dataset = Dataset.from_pandas(pd.DataFrame(data=finetuning_dataset))\n","# finetuning_dataset.push_to_hub(dataset_path_hf)"],"metadata":{"id":"djcy3guBSq2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lpDeCTxNSrtF"},"execution_count":null,"outputs":[]}]}