{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNV7kISrbMIYpRvWDEpH+Qb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qsO5ID3L5WK9"},"outputs":[],"source":["# L1 Language Models, the Chat Format and Tokens"]},{"cell_type":"code","source":["## Setup\n","#### Load the API key and relevant Python libaries.\n","In this course, we've provided some code that loads the OpenAI API key for you."],"metadata":{"id":"1CgGUN7iAOXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import openai\n","import tiktoken\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv()) # read local .env file\n","\n","openai.api_key  = os.environ['OPENAI_API_KEY']"],"metadata":{"id":"eDcK5_0XAPjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### helper function\n","This may look familiar if you took the earlier course \"ChatGPT Prompt Engineering for Developers\" Course"],"metadata":{"id":"ad7hLPMdARHa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=0,\n","    )\n","    return response.choices[0].message[\"content\"]"],"metadata":{"id":"7EinwoFjASRw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Prompt the model and get a completion"],"metadata":{"id":"U3gMQqBgATwo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = get_completion(\"What is the capital of France?\")"],"metadata":{"id":"lPQcluu3AVCB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"id":"LthGyFAUAWcu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Tokens"],"metadata":{"id":"nt1mPH8JAXrJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = get_completion(\"Take the letters in lollipop \\\n","and reverse them\")\n","print(response)"],"metadata":{"id":"WLbkcIYRAYmb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"lollipop\" in reverse should be \"popillol\""],"metadata":{"id":"yhj39nBjAZgN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = get_completion(\"\"\"Take the letters in \\\n","l-o-l-l-i-p-o-p and reverse them\"\"\")"],"metadata":{"id":"RYXwkQwCAhb7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response"],"metadata":{"id":"OQoi5FtFAjpk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Helper function (chat format)\n","Here's the helper function we'll use in this course."],"metadata":{"id":"wF9BLCDPAoJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_completion_from_messages(messages,\n","                                 model=\"gpt-3.5-turbo\",\n","                                 temperature=0,\n","                                 max_tokens=500):\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature, # this is the degree of randomness of the model's output\n","        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut\n","    )\n","    return response.choices[0].message[\"content\"]"],"metadata":{"id":"CXYwyGKbApja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messages =  [\n","{'role':'system',\n"," 'content':\"\"\"You are an assistant who\\\n"," responds in the style of Dr Seuss.\"\"\"},\n","{'role':'user',\n"," 'content':\"\"\"write me a very short poem\\\n"," about a happy carrot\"\"\"},\n","]\n","response = get_completion_from_messages(messages, temperature=1)\n","print(response)"],"metadata":{"id":"SWx0pEonAq-o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# length\n","messages =  [\n","{'role':'system',\n"," 'content':'All your responses must be \\\n","one sentence long.'},\n","{'role':'user',\n"," 'content':'write me a story about a happy carrot'},\n","]\n","response = get_completion_from_messages(messages, temperature =1)\n","print(response)"],"metadata":{"id":"XXJdIAA9Askb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# combined\n","messages =  [\n","{'role':'system',\n"," 'content':\"\"\"You are an assistant who \\\n","responds in the style of Dr Seuss. \\\n","All your responses must be one sentence long.\"\"\"},\n","{'role':'user',\n"," 'content':\"\"\"write me a story about a happy carrot\"\"\"},\n","]\n","response = get_completion_from_messages(messages,\n","                                        temperature =1)\n","print(response)"],"metadata":{"id":"thaAdPrAAtt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_completion_and_token_count(messages,\n","                                   model=\"gpt-3.5-turbo\",\n","                                   temperature=0,\n","                                   max_tokens=500):\n","\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature,\n","        max_tokens=max_tokens,\n","    )\n","\n","    content = response.choices[0].message[\"content\"]\n","\n","    token_dict = {\n","'prompt_tokens':response['usage']['prompt_tokens'],\n","'completion_tokens':response['usage']['completion_tokens'],\n","'total_tokens':response['usage']['total_tokens'],\n","    }\n","\n","    return content, token_dict"],"metadata":{"id":"TFB2lt5ZAxDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messages = [\n","{'role':'system',\n"," 'content':\"\"\"You are an assistant who responds\\\n"," in the style of Dr Seuss.\"\"\"},\n","{'role':'user',\n"," 'content':\"\"\"write me a very short poem \\\n"," about a happy carrot\"\"\"},\n","]\n","response, token_dict = get_completion_and_token_count(messages)"],"metadata":{"id":"g8rENwaDAy5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"id":"OAxXKd-xA0Oq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(token_dict)"],"metadata":{"id":"Z0jH2c3LA1nF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Notes on using the OpenAI API outside of this classroom\n","\n","To install the OpenAI Python library:\n","```\n","!pip install openai\n","```\n","\n","The library needs to be configured with your account's secret key, which is available on the [website](https://platform.openai.com/account/api-keys).\n","\n","You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n"," ```\n"," !export OPENAI_API_KEY='sk-...'\n"," ```\n","\n","Or, set `openai.api_key` to its value:\n","\n","```\n","import openai\n","openai.api_key = \"sk-...\"\n","```"],"metadata":{"id":"j48RVbK-A2yD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### A note about the backslash\n","- In the course, we are using a backslash `\\` to make the text fit on the screen without inserting newline '\\n' characters.\n","- GPT-3 isn't really affected whether you insert newline characters or not.  But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance."],"metadata":{"id":"whxxqTxNA4w0"},"execution_count":null,"outputs":[]}]}